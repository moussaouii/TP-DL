{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST: convolution network\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le but de ce notebook est de classer chiffres écrits à la main de dataset MNIST en dix ensembles: de 0 à 9. Cela se fera à l'aide d'un   convolutional neural network  à 3 couches (comprenant un\"input layer\" et un \"hidden layers\" et un \"output layer\")."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data.dataloader as dataloader\n",
    "import torch.optim as optim\n",
    "\n",
    "from torch.utils.data import TensorDataset\n",
    "from torch.autograd import Variable\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import MNIST\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "SEED = 1\n",
    "\n",
    "# CUDA?\n",
    "cuda = torch.cuda.is_available()\n",
    "\n",
    "# For reproducibility\n",
    "torch.manual_seed(SEED)\n",
    "\n",
    "if cuda:\n",
    "    torch.cuda.manual_seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset MNIST\n",
      "    Number of datapoints: 60000\n",
      "    Split: train\n",
      "    Root Location: ./data\n",
      "    Transforms (if any): Compose(\n",
      "                             ToTensor()\n",
      "                             Normalize(mean=(0.1307,), std=(0.3081,))\n",
      "                         )\n",
      "    Target Transforms (if any): None\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# normalize will center around -1 1\n",
    "trans = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))])\n",
    "train = MNIST('./data', train=True, download=True, transform=trans, )\n",
    "\n",
    "test = MNIST('./data', train=False, download=True, transform=trans, )\n",
    "\n",
    "\n",
    "print (train)\n",
    "# Create DataLoader\n",
    "dataloader_args = dict(shuffle=True, batch_size=256,num_workers=4, pin_memory=True) if cuda else dict(shuffle=True, batch_size=64)\n",
    "train_loader = dataloader.DataLoader(train, **dataloader_args)\n",
    "test_loader = dataloader.DataLoader(test, **dataloader_args)\n",
    "\n",
    "\n",
    "train_data = train.transform(train.train_data.numpy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One hidden Layer NN\n",
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, kernel_size=5, stride=1, padding=2),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(32, 64, kernel_size=5, stride=1, padding=2),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "        self.drop_out = nn.Dropout()\n",
    "        self.fc1 = nn.Linear(7 * 7 * 64, 1000)\n",
    "        self.fc2 = nn.Linear(1000, 10)\n",
    "    def forward(self, x):\n",
    "        out = self.layer1(x)\n",
    "        out = self.layer2(out)\n",
    "        out = out.reshape(out.size(0), -1)\n",
    "        #out = self.drop_out(out)\n",
    "        out = self.fc1(out)\n",
    "        out = self.fc2(out)\n",
    "        return F.log_softmax(out, dim=0)    \n",
    "    \n",
    "    \n",
    "model = Model()\n",
    "if cuda:\n",
    "    model.cuda()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Train Epoch: 1/5 [60000/60000 (100%)]\tLoss: 0.455172\t Test Accuracy: 97.3100%\n",
      " Train Epoch: 2/5 [12864/60000 (21%)]\tLoss: 0.162816"
     ]
    }
   ],
   "source": [
    "EPOCHS = 5\n",
    "losses = []\n",
    "\n",
    "# Eval\n",
    "evaluate_x = Variable(test_loader.dataset.test_data.type_as(torch.FloatTensor()))\n",
    "evaluate_y = Variable(test_loader.dataset.test_labels)\n",
    "evaluate_x = evaluate_x.unsqueeze_(1)\n",
    "if cuda:\n",
    "    evaluate_x, evaluate_y = evaluate_x.cuda(), evaluate_y.cuda()\n",
    "train_size = len(train_loader.dataset)\n",
    "batch_size = (train_size / 256) if (cuda) else  (train_size / 64)\n",
    "\n",
    "model.train()\n",
    "for epoch in range(EPOCHS):\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        # Get Samples\n",
    "        data, target = Variable(data), Variable(target)\n",
    "        \n",
    "        if cuda:\n",
    "            data, target = data.cuda(), target.cuda()\n",
    "        \n",
    "        # Init\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Predict\n",
    "        y_pred = model(data) \n",
    "\n",
    "         \n",
    "        # Calculate loss\n",
    "        loss = F.cross_entropy(y_pred, target)\n",
    "        losses.append(loss.cpu().item())\n",
    "        # Backpropagation\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        \n",
    "        # Display\n",
    "        if batch_idx % 100 == 1:\n",
    "            print('\\r Train Epoch: {}/{} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch+1,\n",
    "                EPOCHS,\n",
    "                batch_idx * len(data), \n",
    "                train_size,\n",
    "                100. * batch_idx / batch_size, \n",
    "                loss.cpu().item()), \n",
    "                end='')\n",
    "            \n",
    "    # display final evaluation for this epoch\n",
    "    model.eval()\n",
    "    output = model(evaluate_x)\n",
    "    pred = output.data.max(1)[1]\n",
    "    d = pred.eq(evaluate_y.data).cpu()\n",
    "    accuracy = d.sum().item()/d.size()[0]\n",
    "    \n",
    "    print('\\r Train Epoch: {}/{} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}\\t Test Accuracy: {:.4f}%'.format(\n",
    "        epoch+1,\n",
    "        EPOCHS,\n",
    "        train_size, \n",
    "        train_size,\n",
    "        100. * batch_idx / batch_size, \n",
    "        loss.cpu().item(),\n",
    "        accuracy*100,\n",
    "        end=''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "output = model(evaluate_x)\n",
    "pred = output.data.max(1)[1]\n",
    "d = pred.eq(evaluate_y.data).cpu()\n",
    "accuracy = d.sum().item()/d.size()[0]\n",
    "print('Accuracy:', accuracy*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_kernels(tensor, num_cols=6):\n",
    "    if not tensor.ndim==4:\n",
    "        raise Exception(\"assumes a 4D tensor\")\n",
    "    num_kernels = tensor.shape[0]\n",
    "    num_rows = 1+ num_kernels // num_cols\n",
    "    fig = plt.figure(figsize=(num_cols,num_rows))\n",
    "    for i in range(tensor.shape[0]):\n",
    "        ax1 = fig.add_subplot(num_rows,num_cols,i+1)\n",
    "        ax1.imshow(tensor[i][0])\n",
    "        ax1.axis('off')\n",
    "        ax1.set_xticklabels([])\n",
    "        ax1.set_yticklabels([])\n",
    "\n",
    "    plt.subplots_adjust(wspace=0.1, hspace=0.1)\n",
    "    plt.show()\n",
    "\n",
    "for m in model.modules():\n",
    "    if isinstance(m, nn.Conv2d):\n",
    "        plot_kernels(m.weight.data.numpy())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
